# TinyGPT Shakespeare Text Generation ğŸ­  

This is my learning project where I trained **TinyGPT** on the **Shakespeare dataset** using **PyTorch**.  
My goal was to understand how transformers work in practice and explore how small language models can be trained from scratch.  

---

## ğŸŒŸ Project Motivation  

I have been curious about how text generation models like GPT actually work under the hood. Instead of just using pre-trained models, I wanted to try training one myself on a classical dataset â€” Shakespeareâ€™s works.  

This project is not about state-of-the-art results but about **learning, experimenting, and building intuition** about deep learning and NLP.  

---

## âš™ï¸ Tech Stack  

- **Framework**: PyTorch ğŸ  
- **Model**: TinyGPT (a minimal GPT implementation)  
- **Dataset**: Shakespeare dataset (`input.txt`)  
- **Task**: Text generation + experimenting with chatbot-like interactions(can be done if finetuned in future with Q/A prompt post- training) 

---

## ğŸ“¦ Installation  

Clone the repository:  

```bash
git clone https://github.com/your-username/nanogpt-shakespeare.git
cd trainer.py
pip install -r requirements.txt
python trainer.py

'''


It will:

Load the Shakespeare dataset.

Train a small GPT model.

Print out generated text after training.



